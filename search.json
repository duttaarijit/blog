[
	
		{
		  "title"    : "Making Airtel 3G dongle work on Mac OS 10.10 Yosemite",
		  "category" : "technology",
		  "url"     : "/technology/making-airtel-3g-dongle-work-on-mac-os-10-dot-10-yosemite/",
		  "date"     : "2014-12-03 00:00:00 +0530",
		  "content"	: "If you use Airtel 3G Dongle (Mine is Huawei E173) on your Mac , and are having issue using the dongel after upgrading to Yosemite , airtel is of little help. They asked me to downgrade the OS to Mavericks!<br /><br />The reason why the dialer software provided by airtel does not work is , that they internally use Apple USB Modem. According to this FAQ on apple support site , your Operating system should be running in 32 bit mode for the modem to work. Yosemite however , is 64 bit.<br /><br />Anyway , I could find multiple ways to overcome the problem. Here I am writing about the most simple one<br /><br />Step 1:<br />Click on this link to download the new compitable driver from Huawei website Mac-V200R003B015D11SP00C983(for Mac10.10).rar<br /><br /><br /><br />Step 2:<br />Open the archive , you will find two files<br /><br />1. Mobile Partner install user guide.docx<br />2. Mobile Partner.zip<br /><br /><br />The word document has detailed instructions with screenshots , on how to install.<br /><br />Step 3:<br />Open the zip file Mobile Partner.zip , you will find Mobile Partner.app. Double click on this file to install the app<br /><br />Step 4:<br />Once installed , start the app and go to Tools -&#62;; Options<br /><br /><br /><br />Step 5:<br />In the Options window , choose “Profile Management” from the left side menu<br /><br /><br /><br />Step 6:<br />Click on “New” button to create a new profile. Give it a name , such as “airtel 3g”. Also , make sure the “Access Number” is set to *99#. Click “Save” , then “Ok”.<br /><br /><br /><br />Step 7:<br />Insert your Dongel into an USB port. You should see “Mobile Partner” application starting automatically. Choose the profile you created in Step 6 (“airtel 3g”) and “Connect”.<br /><br /><br /><br />That’s it.<br /><br />"
		} ,
	
		{
		  "title"    : "IT Career - Pitfalls to avoid",
		  "category" : "career",
		  "url"     : "/career/it-career-pitfalls-to-avoid/",
		  "date"     : "2014-09-22 00:00:00 +0530",
		  "content"	: "It is very humbling when a youngster walks up to us and says “Thanks for helping me get my first job”. While we are delighted at one end , we are worried at the other.  Why? Because , most of the time a fledgling mind does not see the disaster ahead! Yes , we mean disaster – 75% of IT professionals of 2011-2014 batches will be unemployed 20 years from now.  And this is assuming IT industry does well !! Looks unlikely? Read on to know more.<br /><br />Indian IT industry has employed around 7 ,50 ,000 professionals from the four batches (2011 , 2012 , 2013 , 2014). An estimated 1 ,50 ,000 of these will leave the Indian IT industry to pursue higher studies and never come back to work for the same industry. That leaves us with 6 ,00 ,000 professionals who will be in the industry for long. The question is: How long? Being highly paid with around 20 years of experience , in the year 2030 , companies would want them to take larger responsibilities and oversee at least 100 professionals under them. Summing it up , these 6 lakh professionals should have 6 crore professionals below them. Assuming IT industry grows at 10% per annum for 20 years (caution - it may already be slowing down) , the whole industry will be just 1.2 crore strong. That means at most 1.2 lakh senior professionals will be needed. What would happen to the rest 4.8 lakh professionals? They would , of course , be unemployed.<br /><br />Difficult to digest? In 1995 , there were approximately 11 ,000 software professionals across all levels. Nearly 50% of them are now citizens of another country or earned enough money from the exponentially growing market (nascent market then) growing market to retire , appropriately called VIP (vested in peace). Another at most 15 ,500 professionals of the same era migrated into IT industry from other industries (like SAP consultants , Supply Chain , Financial professionals). So that is a conservative 21 ,000 senior professionals in the whole of Indian IT industry. Many of these who lose a job today struggle to find another suitable profile (20 Yrs of experience) and this is when growth rates in this period have been over 25%. You can see it happening for the current 40+ year old professionals!!<br /><br />Now you have a lingering doubt – could there be something wrong in the projections? Yes !! But it is unfortunately on the negative side. What if the industry grows slower than 10% (may be another bad patch of no growth for 2-4 years). What if automation makes many more jobs redundant (now in IT itself , think about it!)? Last but not the least , another country taking away jobs from India (like China did in manufacturing)?<br /><br />A tell-a-tale from not very long ago is the textile mills of Bombay. They were teeming with activity and nothing could go wrong for them in 1970s and early 1980s. It could only get better as population was growing and people’s ability to spend was increasing. These very mills today are malls!! It can be argued to be a ‘crowding out’ phenomenon , surely not applicable to sunrise IT industry. Or maybe it is visible only in hindsight !!!<br /><br />What are we doing at eLitmus to help the cause?<br /><br /><br />  <br />    We are pushing companies not to lower the entry barriers. We have found that immediately after a slow down year , quality and quantity of candidates improve. Quantity ok , but how quality? You call it competition , you call it lowered demand or call it buyers market. So if companies can adopt the quality principals in this period , why not in growth phase as well. It will help students also.<br />We strongly believe a youngster`s ability to adapt and evolve is much higher than an older person. So push them today rather than tomorrow. If you remember your grandparents had the fitness and ability to walk kilometres at their old age (not spoilt by automobiles when they were a child)<br />  <br />  <br />    Educating students that the easy path out , though rosy for short term , will destroy them. We want them to go that extra mile. That explains our rigorous question paper which tests fundamentals and concepts. We want them to earn their job rather than get it. In the process their ability goes up. Few students who wrote pH test in the initial years of eLitmus have founded their own start-ups.<br />  <br />  <br />    Ensuring start-ups and companies with great work environment do not struggle for lack of talent. Most of these engagements are loss making. We survive thanks to the fact that most of our colleagues at eLitmus are passionate about what they do and work at a fraction of their market salary!!<br />  <br /><br /><br />We are committed to “making India competitive” and we hope we have challenged the young reader of this blog to go the extra mile. As Steve Jobs once quoted the Whole Earth catalogue “Stay hungry , Stay foolish!”<br /><br />"
		} ,
	
		{
		  "title"    : "How we host our blog on GitHub pages and yet serve it from our own Sub-URL",
		  "category" : "technology",
		  "url"     : "/technology/how-we-host-our-blog-on-github-pages-and-yet-serve-it-from-our-own-sub-url/",
		  "date"     : "2014-08-18 00:00:00 +0530",
		  "content"	: "There are umpteen number of blog posts telling you how to host your static site on GitHub Pages for free. They also tell you how to serve such a site from your own domain name.<br /><br />As you may have guessed , this blog is also hosted on GH Pages. Don’t believe me? try visiting this URL https://shireeshj.github.io/blog/<br /><br />It is easy to map a github.io url such as this , to a subdomain. For example , it is easy to map the url to https://blog.elitmus.com/blog/.  All you need to do is check-in a file named CNAME into the root folder of your git repo that contains your static site.<br /><br />What if you want your static site to be served from domain apex? That is easy too.  GitHub pages help explains this in a simple manner. <br /><br />However , If your domain apex is already taken , say by your other website , you have a problem.  To host your static site on a domain apex (or a sub-url of domain apex) the domain apex should be available exclusively for use by github pages.<br /><br />We had to overcome this very problem , since our business website is already hosted on elitmus.com (and www.elitmus.com).  Given that we are not in great love with subdomains. We had to find a workaround. And here is what we did:<br /><br />Since we use nginx to server our business website , all we had to do was to write a simple traffic-cop rule. What this rule did was , to parse the request url to see if it starts with /blog/. If yes , then the request is reverse proxied to GitHub Pages. If no , then it is served from local disk. <br /><br />The relevant lines from the config file are here<br /><br /><br/>location /blog/ {<br /><br/>    proxy_pass       http://shireeshj.github.io/;<br /><br/>    proxy_redirect off;<br /><br/>    proxy_set_header Host &#60;;shireeshj.github.io&#62;;;<br /><br/>    proxy_set_header X-Host &#60;;shireeshj.github.io&#62;;;;<br /><br/>    proxy_set_header X-Real-IP $remote_addr;<br /><br/>    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;<br /><br/>  }<br /><br /><br />This is how we get free hosting for our blog , yet serve it from our official URL. If GitHub pages ever stops us from reverse proxying , we shall simply spin our own webserver to run this static site and reverse proxy to that web server.<br /><br />"
		} ,
	
		{
		  "title"    : "Using Monit to get email alert on unauthorized login",
		  "category" : "technology",
		  "url"     : "/technology/using-monit-to-get-email-alert-on-unauthorized-login/",
		  "date"     : "2014-06-04 00:00:00 +0530",
		  "content"	: "For a long time , we had our own custom written perl script to alert us whenever someone logged into our production servers from an ip address we do not recognize (not whitelisted). The script looked somewhat like this…<br /><br />#!/usr/bin/perl<br /># script file: alert_on_login.pl<br />#<br />my $login_str = &ldquo;Accepted publickey&ldquo;<br />my $whitelist_ip = &ldquo;122.123.123.111&ldquo;<br /><br />sub sendEmail<br />{<br />        my ($to , $from , $subject , $message) = @_;<br />        my $sendmail = &amp;#39;/usr/lib/sendmail&amp;#39;;<br />        open(MAIL , &ldquo;|$sendmail -oi -t&ldquo;);<br />        print MAIL &ldquo;From: $from&ldquo;<br />        print MAIL &ldquo;To: $to&ldquo;<br />        print MAIL &ldquo;Subject: $subject&ldquo;<br />        print MAIL &ldquo;$message&ldquo;<br />        close(MAIL);<br />}<br /><br />while (&#60;;&#62;;) {<br />        if (grep(/$login_str/ , $_) &amp;amp;&amp;amp; !grep(/$whitelist_ip/ , $_)) {<br />                print $_;<br />                chomp $_;<br />                @arr = split(&amp;#39; &amp;#39; , $_);<br />                sendEmail(&amp;#39;recepient1@elitmus.com , recepient2@elitmus.com&amp;#39; ,<br />                          &amp;#39;monit@elitmus.com&amp;#39; ,<br />                          &amp;#39;Server login from &amp;#39; . $arr[10] ,<br />                          $_);<br />        }<br />}<br /><br />All we needed to do was to run this script in the background as a daemon , and it would send us an email alert whenever someone logged in successfully. As root user start the script like this:<br /><br />  # (perl alert_on_login.pl /var/log/auth.log &amp;amp;)<br /><br /><br />Ever since we started using monit for the usual purpose (monitoring processes) , we have also entrusted monit to do the job of the above perl script. Monit makes this super simple…<br /><br />Monit is a popular opensource process monitoring tool. It is used mostly for monitoring health of any linux process and take necessary action if any of the set parameters are breached. Monit can restart a process if the process failed for some reason. Monit can also notify you of incidents and actions taken.<br /><br />See this to learn more about monit’s alert capabilities.<br /><br />Monit’s global configuration file is usually /etc/monit/monitrc. Here is what monit needs to be told about how to send email alerts:<br /><br />...<br /># This is our SMTP server settings. The complete syntax is<br /># SET MAILSERVER &#60;;hostname [PORT] [USERNAME] [PASSWORD] [using SSLAUTO|SSLV2|SSLV3|TLSV11|TLSV12] [CERTMD5 checksum]&#62;; , ...<br />#          [with TIMEOUT X SECONDS]<br />#          [using HOSTNAME hostname]<br />#<br /># But for our purpose , localhost is good enough<br />SET mailserver localhost<br /><br /># This is the email template for alert messages<br />SET mail-format {<br />  from: monit@elitmus.com<br />  subject: $SERVICE $EVENT at $DATE<br />  message: Monit $ACTION $SERVICE at $DATE on $HOST: $DESCRIPTION.<br />           Yours sincerely ,<br />           monit<br />}<br /><br /># Alerts can be triggered for various reasons. Successful ssh login is just one of those reasons.<br /># Since this is a global configuration , we can tell monit to not send alerts for certain events<br />#  We also specify the email address of the recepient who will receive the alerts<br /><br />set alert recepient1@elitmus.com NOT ON { action , instance , pid , ppid , nonexist }<br />...<br /><br />And then we add this config file ssh_logins.conf specific to sshd related stuff:<br /><br />check file ssh_logins with path /var/log/auth.log<br />  ignore match &ldquo;/etc/monit/whitelist_ips.regex&ldquo;<br />  if match &ldquo;Accepted publickey&ldquo; then alert<br /><br />Notice how we tell monit to ignore logins from known ip addresses. We can now store all whitelist ip addresses in a separate file /etc/monit/whitelist_ips.regex , one address per line.<br /><br />Note: We have disabled password based login and hence do not monitor for passworded logins. If you use passworded login , you should change &quot;Accepted publickey&quot; to &quot;Accepted password&quot;<br /><br />Happy monitoring!<br /><br />"
		} ,
	
		{
		  "title"    : "Gotcha&#39;s while syntactically translating AES encryption logic from PHP to Ruby",
		  "category" : "technology",
		  "url"     : "/technology/gotchas-while-syntactically-translating-aes-encryption-logic-from-php-to-ruby/",
		  "date"     : "2014-05-25 00:00:00 +0530",
		  "content"	: "Our Payment Gateway service provider recently launched a new platform with some nice-to-have features. We wanted those features and so we decided to migrate. Being one of the earliest adopters of the new platform , there was no integration kit available. We had to build it ourselves. Not a problem. Since we are a Ruby On Rails shop , we built our own Ruby integration kit. All went well and we pushed it to production.<br /><br />A month or two later , we got an email from our gateway provider seeking our help with writing the encryption and decryption logic for the Ruby integration kit they were developing. We were a little surprised , because we noticed they had already published integration kits for PHP , Python , JAVA etc. How difficult can it be to translate that to Ruby?<br /><br />Turns out , syntactic transalation of code from one programming language to another does not always work. A slightly more deeper knowledge helps. We could almost guess where they were getting stuck.<br /><br />Before we get to the story , some backgroung on the encryption algo will add clarity.<br /><br />For secure communication between our server and the gateway , the prescribed cipher was AES , specifically symmetric-key block cipher with a 128 bit secret key in CBC mode. Since OpenSSL already implements this algo and is avaliable on almost all platforms , most programming languages just bundle a wrapper for OpenSSL.<br /><br />So if its the same OpenSSL that the wrappers call , why couldn’t the gateway service provider translate their own PHP code to Ruby?<br /><br />Here is why:<br /><br />AES works by breaking the plain text (the text to be encrypted) into blocks of 128 bits (or 16 bytes). In CBC mode , each block is XORed with the key to get cipher text of that block. The cipher text of the previous block is used for encrypting the next block… so on and so forth , until all the blocks are encrypted.<br /><br />Note that the length of the cipher text will be exactly same as that of the plain text.<br /><br />The problem occures with the last block. If the length of the plain text is not a multiple of 128. the last block will be shorter than 128 bits. Since the algo can work only on blocks of 128 bits , It is a common practice to pad the last block so that it becomes equal to 128 bits in lenght. This padding is subsequently discarded after decryption.<br /><br />Note: The actual algo is more complicated than this. We have deliberately left out details that are not relevent for this post.<br /><br />This is the encryption method in the PHP integration kit published by the gateway service provider<br /><br /> 1 function encrypt($plainText ,$key)<br /> 2 {<br /> 3   $secretKey = hextobin(md5($key));<br /> 4   $initVector = &ldquo;...&ldquo;<br /> 5   $openMode = mcrypt_module_open(MCRYPT_RIJNDAEL_128 , &amp;#39;&amp;#39; ,&amp;#39;cbc&amp;#39; , &amp;#39;&amp;#39;);<br /> 6   $blockSize = mcrypt_get_block_size(MCRYPT_RIJNDAEL_128 , &amp;#39;cbc&amp;#39;);<br /> 7 <br /> 8   $plainPad = pkcs5_pad($plainText , $blockSize);  //  &#60;;---- Padding<br /> 9 <br />10   if (mcrypt_generic_init($openMode , $secretKey , $initVector) != -1) <br />11   {<br />12     $encryptedText = mcrypt_generic($openMode , $plainPad);<br />13     mcrypt_generic_deinit($openMode);      <br />14   } <br />15   return bin2hex($encryptedText);<br />16 }<br />17 <br />18 // Padding method<br />19 function pkcs5_pad ($plainText , $blockSize)<br />20 {<br />21   // padding logic here<br />22 }<br /><br />And here is the same implemented in Ruby<br /><br />1 def self.encrypt(plain_text , key)<br />2     secret_key     = Digest::MD5.digest(key)<br />3     cipher         = OpenSSL::Cipher::AES.new(128 , :CBC)<br />4     cipher.encrypt<br />5     cipher.key     = secret_key<br />6     cipher.iv      = INIT_VECTOR<br />7     encrypted_text = cipher.update(plain_text) + cipher.final<br />8     return (encrypted_text.unpack(&ldquo;H*&ldquo;)).first<br />9 end<br /><br />Notice any difference?<br /><br />It turns out that , unlike in Python , PHP and few other languages , Ruby wrapper for OpenSSL automatically takes care of padding (default behaviour). This is clearly mentioned in the documentation. For some reason , techies at our gateway service provider overlooked this and hit a dead-end.<br /><br />By the they , they were gracious enough to acknowledge our contribution in their Ruby Integration Kit (accessible only to their subscribers)<br /><br />But We have open sourced our code here ‘cca_crypto’. We have plans of make this into a complete package - with view generators etc. , and publish this as a rubygem. We shall gladly accept any pull request!<br /><br />"
		} ,
	
		{
		  "title"    : "Setting Up Amazon RDS as a Slave to a self-managed MySQL server",
		  "category" : "technology",
		  "url"     : "/technology/setting-up-amazon-rds-as-a-slave-to-a-self-managed-mysql-server/",
		  "date"     : "2014-05-21 00:00:00 +0530",
		  "content"	: "Last week , we migrated our MySQL database server , which was running on an EC2 instance , to RDS. We hoped the migration process would be smooth.<br /><br />As always , migrating a large database has its challenges. Business folks expect the minimum possible downtime.<br /><br />The plan was simple.<br /><br /><br />  Launch an RDS instance<br />  Load a full dump into it<br />  Configure it to act as a slave of the self-managed server (current master)<br />  On the D-day , pull the website down and promote the RDS instance to take over as the new master<br /><br /><br />We soon discovered that RDS comes with curtailed root permissions. There are several commands that are disallowed. Some of these include “CHANGE MASTER TO….”<br /><br />What do we do now?<br /><br />One option was to carry out the migration in one go , while the website was offline. This meant the downtime would have been several hours , instead of minutes. Obviously , not an acceptable option at all.<br /><br />Some R&amp;amp;D was all it took to discover how to proceed with the original approach.<br /><br />RDS comes with a bunch of stored procedures , which help you configure it as a slave. There is almost a one-to-one mapping of these stored procedures with the commands that are disallowed.<br /><br /><br />MySQL CommandCorrosponding Stored Proc<br />CHANGE MASTER TOmysql.rds_set_external_master<br />START SLAVEmysql.rds_start_replication<br />STOP SLAVEmysql.rds_stop_replication<br />RESET MASTERmysql.rds_reset_external_master <br /><br /><br />So , Using these stored procedures , you can now configure your RDS instance as a slave to your self-managed MySQL server<br /><br />After loading a full dump to RDS , Call the stored procedure mysql.rds_set_external_master like this<br /><br />CALL mysql.rds_set_external_master (&#39;servername&#39; , port , &#39;user&#39; , &#39;password&#39; , &#39;binlog-file&#39; , binlog-offset , 0);<br /><br /><br />Then<br /><br />CALL mysql.rds_start_replication;<br /><br /><br />This will make RDS a slave of your self managed mysql server. You can run “SHOW SLAVE STATUS” to see its working.<br /><br />When it is time to promote RDS to master. You call these stored procedures<br /><br />CALL mysql.rds_stop_replication;<br /><br />CALL mysql.rds_reset_external_master;<br /><br /><br />That’s it. Now point your applications to the RDS instance and take your site live.<br /><br />Note:<br /><br />For your RDS to work as a slave , it needs permissions to connect to port 3306 of your current master. Make sure you open this port for the RDS instance.<br /><br />You can run the following command to find out the ip address of your rds instance<br /><br />ping -c rdsname.cpesx66wwe7y.ap-southeast-1.rds.amazonaws.com<br /><br />"
		} ,
	
		{
		  "title"    : "Beware of creating $HOME/.ssh folder by hand, when SELinux is turned on",
		  "category" : "technology",
		  "url"     : "/technology/beware-of-creating-ssh-folder-by-hand-when-selinux-is-turned-on/",
		  "date"     : "2012-07-22 00:00:00 +0530",
		  "content"	: "I was experimenting with chef to manage our Linux boxes. As a standard practice , our application user deployer is homed in /applications/deployer rather than the usual /home/deployer.<br /><br />To enable password less login , I appended my public key to ~/.ssh/authorized_keys <br /><br /> ssh-copy-id -i ~/.ssh/id_rsa deployer@remote.server<br /><br /><br />The first time I run this command , I will be prompted for a password to install my key. After this , I can run the below command to login without a password:<br /><br />ssh -i ~/.ssh/id_rsa deployer@remote.server<br /><br /><br />However , that did not work as expected.<br /><br />For some reason , sshd was unable to read the authorized_keys file. I checked all the usual things.. all looked fine. Everything seem to work just fine when SELinux was running in permissive mode on the remote server , but not when it was in enforcing mode.<br /><br />Discovered that if .ssh folder was created by hand (or even the folder containing .ssh folder) , we need to do few additional things.<br /><br />Step 1: <br /><br />Open this file /etc/selinux/targeted/contexts/files/file_contexts.homedirs and append the following line to the bottom<br /><br /> /applications/deployer/[^/]*/ssh(/.*)?     system_u:object_r:ssh_home_t:s0<br /><br /><br />Note: remember to adjust the path as per your needs.<br /><br />Step 2: run the following command<br /><br />restorecon -R -v /applications/deployer/.ssh<br /><br /><br />Again , remember to adjust the path as per your needs.<br /><br />Now you are all set!<br /><br /> ssh -i ~/.ssh/id_rsa deployer@remote.server<br /><br /><br />should log you in without asking for a password!<br />"
		} ,
	
		{
		  "title"    : "Importance of Date field in an email&#39;s Header",
		  "category" : "technology",
		  "url"     : "/technology/importance-of-date-field-in-an-emails-header/",
		  "date"     : "2012-04-04 00:00:00 +0530",
		  "content"	: "So far , we paid little attention to email delivery issues. We knew delivering to rediffmail is a pain. So we discouraged our users from using rediffmail. Apart from that we had FCrDNS and SPF configured and working fine. We had also configured DKIM. And then a month ago , we also added DMARC in monitor mode.<br /><br />We were happy! Until…<br /><br />Recently , we started getting loads of phishing emails from what appeared to originate from our own domain name [not our servers].<br /><br />It told us two things. <br /><br /><br />  eLitmus.com was growing in popularity<br />  We cannot ignore email delivery issue any longer<br /><br /><br />We ran our email through Spam Assassin checks and were surprised to see that we got a score of 6. Anything above 5 is BAD. It’s a straight spam! But we knew we were not spamming. These were transactional emails triggered by our website on certain events , such as New registration , or Forgot Password.<br /><br />It was almost by accident , we noticed that the timezone in the Date header of the email was appearing as +0580. Indian Standard Time (IST) is 5 hours and 30 minutes ahead of UTC. So this value should have been +0530 , not +0580. Apparently , that is good enough reason for Spam Assassin to treat our mails as spam.<br /><br />Tracing backwards , we discovered a bug in our application code and fixed it. It was a single line fix.<br /><br />With this change , Spam Assassin was happy to give us a score of zero.<br /><br />That is just one part of one header. There are ten others which have to be configured correctly.<br /><br />Here is an article with good insights in to how gmail calculates sender reputation. Its a little dated , but still relevent. Sender reputation in a large webmail service (PDF)<br /><br />By the way , here is a nice and free JSon API to check your email’s reputation.<br /><br />"
		} 
	
]